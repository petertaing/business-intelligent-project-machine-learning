{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IS470_lab11.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13Ewpcs3Nv9t"
      },
      "source": [
        "#IS 470 Lab 11: Recommender systems and social network analysis\n",
        "\n",
        "---\n",
        "In this lab, we will first build recommender systems based on movie rating data. \n",
        "We then perform social network analysis based on a small Facebook data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ptb1cxRBXzNS"
      },
      "source": [
        "## Part 1: Recommender Systems<br>\n",
        "We will use the MovieLense data set (downloaded from http://www.grouplens.org/), which contains around 100,000 ratings (1-5) from 943 users on 1682 movies.<br> \n",
        "<br>\n",
        "In this MovieLense data set, each row corresponds to a user, and each column corresponds to a movie.<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKqVXzbWOAyl"
      },
      "source": [
        "###1. Upload and clean data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN5GlqkdOAyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7833b1dd-c796-4016-cca4-6da96bc5a991"
      },
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB0z7Bl3OAym"
      },
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TreFR3tOOAym"
      },
      "source": [
        "# Read user data\n",
        "u_columns = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
        "users = pd.read_csv('/content/drive/MyDrive/IS470_data/u.user', sep='|', names=u_columns)\n",
        "users"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU0EyniGh3JS"
      },
      "source": [
        "# Read movie data\n",
        "m_columns = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']\n",
        "movies = pd.read_csv('/content/drive/MyDrive/IS470_data/u.item', sep='|', names=m_columns, usecols=range(5), encoding='latin-1')\n",
        "movies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZN0y1erh5c8"
      },
      "source": [
        "# Read rating data\n",
        "r_columns = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "ratings = pd.read_csv('/content/drive/MyDrive/IS470_data/u.data', sep = '\\t', names=r_columns)\n",
        "ratings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cKBWBheiScy"
      },
      "source": [
        "# create one merged DataFrame\n",
        "movie_ratings = pd.merge(movies, ratings)\n",
        "MovieLense = pd.merge(movie_ratings, users)\n",
        "MovieLense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__UY8gZSOAym"
      },
      "source": [
        "# Show the head of data frame\n",
        "MovieLense.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_hfK-RpOAyn"
      },
      "source": [
        "###2. Explore the MovieLense data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE0PPBSMOAyn"
      },
      "source": [
        "# Rating information\n",
        "MovieLense['rating'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN15gHk9kd2n"
      },
      "source": [
        "# Rating distribution\n",
        "sns.countplot(x='rating', data=MovieLense)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfxzlCPBnZ-4"
      },
      "source": [
        "# Partition the data\n",
        "target = MovieLense['rating']\n",
        "predictors = MovieLense[['user_id', 'movie_id', 'rating']]\n",
        "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size=0.3, random_state=0)\n",
        "print(predictors_train.shape, predictors_test.shape, target_train.shape, target_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bboolXRhwhKL"
      },
      "source": [
        "# Create user-item matrix for training and testing data\n",
        "train_matrix = np.zeros([len(users), len(movies)])\n",
        "for line in predictors_train.itertuples():\n",
        "  train_matrix[line.user_id-1, line.movie_id-1] = line.rating\n",
        "\n",
        "test_matrix = np.zeros([len(users), len(movies)])\n",
        "for line in predictors_test.itertuples():\n",
        "  test_matrix[line.user_id-1, line.movie_id-1] = line.rating"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt0XU6fmplzw"
      },
      "source": [
        "### 3. Recommender systems"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M-D29Zxy6Mv"
      },
      "source": [
        "# calculate the average rating for each user\n",
        "average_user_rating = np.true_divide(train_matrix.sum(1),(train_matrix!=0).sum(1))\n",
        "\n",
        "# create a train_matrix_sp represents users' preferences on different movies\n",
        "train_matrix_sp = csr_matrix(train_matrix, dtype=np.float64)\n",
        "nz = train_matrix_sp.nonzero()\n",
        "train_matrix_sp[nz] -= average_user_rating[nz[0]]\n",
        "train_matrix_sp = train_matrix_sp.toarray()\n",
        "\n",
        "# calculate the user and movie similarity\n",
        "user_similarity = pairwise_distances(train_matrix_sp)\n",
        "movie_similarity = pairwise_distances(train_matrix_sp.T)\n",
        "np.fill_diagonal(user_similarity, 0)\n",
        "np.fill_diagonal(movie_similarity, 0)\n",
        "print(user_similarity)\n",
        "print(movie_similarity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubrWDbDp0aA2"
      },
      "source": [
        "# Create a collaborative filtering algorithm\n",
        "zero_index = np.zeros(train_matrix_sp.shape)\n",
        "zero_index[nz] = 1\n",
        "def collaborative_filtering (type = 'user'):\n",
        "  if type == 'user':\n",
        "    pre_rating = average_user_rating[:, np.newaxis] + np.dot(user_similarity, train_matrix_sp)/np.dot(user_similarity, zero_index)\n",
        "  if type == 'item':\n",
        "    pre_rating = (np.dot(movie_similarity, train_matrix.T)/np.dot(movie_similarity, zero_index.T)).T\n",
        "  return pre_rating\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIUd8mf3EaGL"
      },
      "source": [
        "# make predictions\n",
        "user_prediction = collaborative_filtering(type='user')\n",
        "item_prediction = collaborative_filtering(type='item')\n",
        "user_prediction = np.nan_to_num(user_prediction, nan=4)\n",
        "item_prediction = np.nan_to_num(item_prediction, nan=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA0c_WBLXlUz"
      },
      "source": [
        "# Examine the evaluation results of user-based collaborative filtering on testing data: MAE and RMSE\n",
        "MAE = mean_absolute_error(test_matrix[test_matrix!=0], user_prediction[test_matrix!=0])\n",
        "RMSE = mean_squared_error(test_matrix[test_matrix!=0], user_prediction[test_matrix!=0], squared=False)\n",
        "print(\"MAE:\", MAE)\n",
        "print(\"RMSE:\", RMSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PDsrgcaSRFH"
      },
      "source": [
        "# Examine the evaluation results of item-based collaborative filtering on testing data: MAE and RMSE\n",
        "MAE = mean_absolute_error(test_matrix[test_matrix!=0], item_prediction[test_matrix!=0])\n",
        "RMSE = mean_squared_error(test_matrix[test_matrix!=0], item_prediction[test_matrix!=0], squared=False)\n",
        "print(\"MAE:\", MAE)\n",
        "print(\"RMSE:\", RMSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6OmLX_vf6JN"
      },
      "source": [
        "Q1. Which recommender system has better performance, user-based or item-based, and why? <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfU5MvLniCsM"
      },
      "source": [
        "## Part 2: Social Network Analysis<br>\n",
        "We will use a small Facebook data from stanford network analysis project: https://snap.stanford.edu/data/ego-Facebook.html.<br> \n",
        "<br>\n",
        "The social network is stored by an edgelist.<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lKC2FW0iTQU"
      },
      "source": [
        "###1. Upload and clean data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKAKJgQziTQU"
      },
      "source": [
        "# Import packages\n",
        "import networkx as nx\n",
        "import seaborn as sns"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To4Z--WNi3QK"
      },
      "source": [
        "# Read data\n",
        "G = nx.read_edgelist(\"/content/drive/MyDrive/IS470_data/facebook_edges.txt\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPlNrm2wKdR_"
      },
      "source": [
        "###2. Social Network Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhnVbnyd3_OI"
      },
      "source": [
        "# Visualize the network (every time you run this line of code, the network will be different)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TjixnGt4SA4"
      },
      "source": [
        "# Number of nodes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-kMtyn64szB"
      },
      "source": [
        "# Number of edges\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atEqRi4g5DDQ"
      },
      "source": [
        "# Network density\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIOolIk15uYJ"
      },
      "source": [
        "# Degree centrality\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJO5FTdT75tg"
      },
      "source": [
        "# Betweenness centrality\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88au_PS69lJf"
      },
      "source": [
        "# Closeness centrality\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_CBgSl2-D-3"
      },
      "source": [
        "# Transitivity\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIE-5tLs-Qiu"
      },
      "source": [
        "# Find and plot the largest cliques (from https://orbifold.net/default/community-detection-using-networkx/)\n",
        "cliques = list(nx.find_cliques(G))\n",
        "max_clique = max(cliques, key=len)\n",
        "node_color = [(0.5, 0.5, 0.5) for v in G.nodes()]\n",
        "for i, v in enumerate(G.nodes()):\n",
        "  if v in max_clique:\n",
        "    print(v)\n",
        "    node_color[i] = (0.9, 0.5, 0.5)\n",
        "nx.draw_networkx(G, node_color=node_color)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7bP6KOjC5lI"
      },
      "source": [
        "# Community detection (from https://orbifold.net/default/community-detection-using-networkx/)\n",
        "def get_color(i, r_off=1, g_off=1, b_off=1):\n",
        "  r0, g0, b0 = 0, 0, 0\n",
        "  n = 16\n",
        "  low, high = 0.1, 0.9\n",
        "  span = high - low\n",
        "  r = low + span * (((i + r_off) * 3) % n) / (n - 1)\n",
        "  g = low + span * (((i + g_off) * 5) % n) / (n - 1)\n",
        "  b = low + span * (((i + b_off) * 7) % n) / (n - 1)\n",
        "  return (r, g, b)  \n",
        "def set_node_community(G, communities):\n",
        "  for c, v_c in enumerate(communities):\n",
        "    for v in v_c:\n",
        "      G.nodes[v]['community'] = c + 1\n",
        "\n",
        "result = nx.community.girvan_newman(G)\n",
        "communities = next(result)\n",
        "set_node_community(G, communities)\n",
        "node_color = [get_color(G.nodes[v]['community']) for v in G.nodes]\n",
        "\n",
        "nx.draw_networkx(G, node_color=node_color)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNRp8uoa-0g0"
      },
      "source": [
        "!jupyter nbconvert --to html \"/content/drive/MyDrive/IS470_lab/IS470_lab11.ipynb\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}